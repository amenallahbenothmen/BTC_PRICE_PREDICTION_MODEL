{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amenm\\\\OneDrive\\\\Desktop\\\\p2m_final\\\\BTC_PRICE_PREDICTION-main\\\\BTC_PRICE_PREDICTION-main\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amenm\\\\OneDrive\\\\Desktop\\\\p2m_final\\\\BTC_PRICE_PREDICTION-main\\\\BTC_PRICE_PREDICTION-main'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/amenallahbenothmen/BTC_PRICE_PREDICTION.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"amenallahbenothmen\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"487600b5c6de91d125db4e8065f79f19d3bcc5a7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path \n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path \n",
    "    trained_model_path:Path\n",
    "    full_model_path :Path\n",
    "    training_data :Path\n",
    "    data_dir :Path\n",
    "    batch_size : int \n",
    "    epochs : int \n",
    "    patience : int \n",
    "    learning_rate: float \n",
    "    all_params : dict \n",
    "    mlflow_uri:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LSTM_BTC_Prediction.constants  import *\n",
    "from src.LSTM_BTC_Prediction.utils.common import read_yaml,create_directories,save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath) \n",
    "        self.params=read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_tarining_config(self) ->TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data=self.config.data_preprocessing.data_final_dir\n",
    "\n",
    "        create_directories([training.root_dir])\n",
    "        training_config=TrainingConfig(\n",
    "            root_dir=training.root_dir,\n",
    "            trained_model_path=training.trained_model_path,\n",
    "            full_model_path=prepare_base_model.full_model_path,\n",
    "            training_data=training_data,\n",
    "            data_dir=self.config.data_preprocessing.data_dir,\n",
    "            batch_size=params.BATCH_SIZE,\n",
    "            epochs=params.EPOCHS,\n",
    "            patience=params.PATIENCE,\n",
    "            learning_rate=params.LEARNING_RATE,\n",
    "            all_params=params,\n",
    "            mlflow_uri=\"https://dagshub.com/amenallahbenothmen/BTC_PRICE_PREDICTION.mlflow\"\n",
    "        )\n",
    "        return training_config\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.LSTM_BTC_Prediction import logger  \n",
    "import numpy as np \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config \n",
    "\n",
    "    def get_base_model(self):\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(self.config.full_model_path)\n",
    "            logger.info(\"Model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error loading model: {e}')\n",
    "\n",
    "    def get_data(self):\n",
    "        try:\n",
    "            self.trainX = np.load(os.path.join(self.config.training_data, \"trainX.npy\"))\n",
    "            self.trainY = np.load(os.path.join(self.config.training_data, \"trainY.npy\"))\n",
    "            self.valX = np.load(os.path.join(self.config.training_data, \"valX.npy\"))\n",
    "            self.valY = np.load(os.path.join(self.config.training_data, \"valY.npy\"))\n",
    "            self.testX = np.load(os.path.join(self.config.training_data, \"testX.npy\"))\n",
    "            self.testY = np.load(os.path.join(self.config.training_data, \"testY.npy\"))\n",
    "            self.df_test = pd.read_csv(os.path.join(self.config.data_dir, \"test.csv\"))\n",
    "            self.df_train = pd.read_csv(os.path.join(self.config.data_dir, \"train.csv\"))\n",
    "            self.df_val = pd.read_csv(os.path.join(self.config.data_dir, \"val.csv\"))\n",
    "            logger.info(\"DATA loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\") \n",
    "\n",
    "    def calculate_rmse(self, y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    def save_score(self, train_loss, val_loss, test_rmse):\n",
    "        self.scores = {\"train_loss\": train_loss, \"val_loss\": val_loss, \"test_rmse\": test_rmse}\n",
    "        save_json(path=Path(\"scores.json\"), data=self.scores)       \n",
    "\n",
    "    def train(self):\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=self.config.learning_rate),\n",
    "            loss='mean_squared_error'\n",
    "        ) \n",
    "        checkpoint_path = self.config.trained_model_path\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_path, \n",
    "            monitor='val_loss',\n",
    "            verbose=1, \n",
    "            save_best_only=True,\n",
    "            mode='min'\n",
    "        )\n",
    "        earlystopping = EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=self.config.patience, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        callbacks = [checkpoint, earlystopping]\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.trainX, \n",
    "            self.trainY, \n",
    "            batch_size=self.config.batch_size,\n",
    "            epochs=self.config.epochs,\n",
    "            verbose=1, \n",
    "            shuffle=False, \n",
    "            validation_data=(self.valX, self.valY),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        max_test = self.df_test['close'].max()\n",
    "        min_test = self.df_test['close'].min()\n",
    "        max_val = self.df_val['close'].max()\n",
    "        min_val = self.df_val['close'].min()\n",
    "        max_train = self.df_train['close'].max()\n",
    "        min_train = self.df_train['close'].min()                \n",
    "\n",
    "        train_loss = history.history['loss'][-1] * (max_train - min_train) + min_train\n",
    "        val_loss = history.history['val_loss'][-1] * (max_val - min_val) + min_val\n",
    "\n",
    "        test_predictions = self.model.predict(self.testX)\n",
    "        test_predictions = test_predictions * (max_test - min_test) + min_test\n",
    "\n",
    "        actual_price = self.testY * (max_test - min_test) + min_test\n",
    "\n",
    "        test_rmse = self.calculate_rmse(actual_price, test_predictions)\n",
    "\n",
    "        self.save_score(train_loss, val_loss, test_rmse)\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"train_loss\": self.scores[\"train_loss\"], \"val_loss\": self.scores[\"val_loss\"], \"test_rmse\": self.scores[\"test_rmse\"]}\n",
    "            )\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"LSTM_BTC_PREDECTION\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-07 19:48:57,763: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-05-07 19:48:57,765: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-07 19:48:57,766: INFO: common: created directory at: artifacts]\n",
      "[2024-05-07 19:48:57,767: INFO: common: created directory at: artifacts/training]\n",
      "[2024-05-07 19:48:57,849: WARNING: legacy_h5_format: No training configuration found in the save file, so the model was *not* compiled. Compile it manually.]\n",
      "[2024-05-07 19:48:57,850: INFO: 1231914917: Model loaded successfully]\n",
      "[2024-05-07 19:48:57,876: INFO: 1231914917: DATA loaded successfully]\n",
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.6237\n",
      "Epoch 1: val_loss improved from inf to 0.42896, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - loss: 0.6202 - val_loss: 0.4290\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.1973\n",
      "Epoch 2: val_loss improved from 0.42896 to 0.12962, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 185ms/step - loss: 0.1967 - val_loss: 0.1296\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0967\n",
      "Epoch 3: val_loss improved from 0.12962 to 0.06932, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 187ms/step - loss: 0.0967 - val_loss: 0.0693\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - loss: 0.0592\n",
      "Epoch 4: val_loss improved from 0.06932 to 0.06681, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - loss: 0.0592 - val_loss: 0.0668\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.0481\n",
      "Epoch 5: val_loss improved from 0.06681 to 0.05517, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 210ms/step - loss: 0.0482 - val_loss: 0.0552\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - loss: 0.0380\n",
      "Epoch 6: val_loss improved from 0.05517 to 0.04108, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 218ms/step - loss: 0.0380 - val_loss: 0.0411\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.0373\n",
      "Epoch 7: val_loss improved from 0.04108 to 0.03667, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - loss: 0.0373 - val_loss: 0.0367\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - loss: 0.0284\n",
      "Epoch 8: val_loss did not improve from 0.03667\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 212ms/step - loss: 0.0284 - val_loss: 0.0381\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - loss: 0.0317\n",
      "Epoch 9: val_loss improved from 0.03667 to 0.02782, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 236ms/step - loss: 0.0318 - val_loss: 0.0278\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.0217\n",
      "Epoch 10: val_loss improved from 0.02782 to 0.02340, saving model to artifacts/training/model.keras\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - loss: 0.0217 - val_loss: 0.0234\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step\n",
      "[2024-05-07 19:50:25,040: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/07 19:50:26 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "Successfully registered model 'LSTM_BTC_PREDECTION'.\n",
      "2024/05/07 19:50:58 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM_BTC_PREDECTION, version 1\n",
      "Created version '1' of model 'LSTM_BTC_PREDECTION'.\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    config=ConfigurationManager()\n",
    "    training_config=config.get_tarining_config()\n",
    "    training=Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.get_data()\n",
    "    training.train()\n",
    "    training.log_into_mlflow()\n",
    "except Exception as e :\n",
    "    raise e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
