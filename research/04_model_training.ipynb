{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amenm\\\\OneDrive\\\\Desktop\\\\p2m_final\\\\BTC_PRICE_PREDICTION_MODEL\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\amenm\\\\OneDrive\\\\Desktop\\\\p2m_final\\\\BTC_PRICE_PREDICTION_MODEL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/amenallahbenothmen/BTC_PRICE_PREDICTION.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"amenallahbenothmen\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"487600b5c6de91d125db4e8065f79f19d3bcc5a7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path \n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path \n",
    "    trained_model_path:Path\n",
    "    full_model_path :Path\n",
    "    training_data :Path\n",
    "    data_dir :Path\n",
    "    model_dir:Path\n",
    "    saved_model_path:Path\n",
    "    prediction_dir:Path\n",
    "    result_path:Path\n",
    "    batch_size : int \n",
    "    epochs : int \n",
    "    patience : int \n",
    "    learning_rate: float \n",
    "    forecast_horizon:int\n",
    "    all_params : dict \n",
    "    mlflow_uri:str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LSTM_BTC_Prediction.constants  import *\n",
    "from src.LSTM_BTC_Prediction.utils.common import read_yaml,create_directories,save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath) \n",
    "        self.params=read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_tarining_config(self) ->TrainingConfig:\n",
    "        training=self.config.training\n",
    "        prepare_base_model=self.config.prepare_base_model\n",
    "        params=self.params\n",
    "        training_data=self.config.data_preprocessing.data_final_dir\n",
    "\n",
    "        create_directories([training.root_dir])\n",
    "        create_directories([training.model_dir])\n",
    "        create_directories([training.prediction_dir])\n",
    "\n",
    "        training_config=TrainingConfig(\n",
    "            root_dir=training.root_dir,\n",
    "            trained_model_path=training.trained_model_path,\n",
    "            full_model_path=prepare_base_model.full_model_path,\n",
    "            training_data=training_data,\n",
    "            data_dir=self.config.data_preprocessing.data_dir,\n",
    "            model_dir=training.model_dir,\n",
    "            saved_model_path=training.saved_model_path,\n",
    "            prediction_dir=training.prediction_dir,\n",
    "            result_path=training.result_path,\n",
    "            batch_size=params.BATCH_SIZE,\n",
    "            epochs=params.EPOCHS,\n",
    "            patience=params.PATIENCE,\n",
    "            learning_rate=params.LEARNING_RATE,\n",
    "            forecast_horizon=params.FORECAST_HORIZON,\n",
    "            all_params=params,\n",
    "            mlflow_uri=\"https://dagshub.com/amenallahbenothmen/BTC_PRICE_PREDICTION.mlflow\"\n",
    "        )\n",
    "        return training_config\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from src.LSTM_BTC_Prediction import logger  \n",
    "import numpy as np \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config \n",
    "\n",
    "    def get_base_model(self):\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(self.config.full_model_path)\n",
    "            logger.info(\"Model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error loading model: {e}')\n",
    "\n",
    "    def get_data(self):\n",
    "        try:\n",
    "            self.trainX = np.load(os.path.join(self.config.training_data, \"trainX.npy\"))\n",
    "            self.trainY = np.load(os.path.join(self.config.training_data, \"trainY.npy\"))\n",
    "            self.valX = np.load(os.path.join(self.config.training_data, \"valX.npy\"))\n",
    "            self.valY = np.load(os.path.join(self.config.training_data, \"valY.npy\"))\n",
    "            self.testX = np.load(os.path.join(self.config.training_data, \"testX.npy\"))\n",
    "            self.testY = np.load(os.path.join(self.config.training_data, \"testY.npy\"))\n",
    "            self.df_test = pd.read_csv(os.path.join(self.config.data_dir, \"test.csv\"))\n",
    "            self.df_train = pd.read_csv(os.path.join(self.config.data_dir, \"train.csv\"))\n",
    "            self.df_val = pd.read_csv(os.path.join(self.config.data_dir, \"val.csv\"))\n",
    "            logger.info(\"DATA loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\") \n",
    "\n",
    "    def calculate_rmse(self, y_true, y_pred):\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "    def save_score(self, train_loss, val_loss, test_rmse):\n",
    "        self.scores = {\"train_loss\": train_loss, \"val_loss\": val_loss, \"test_rmse\": test_rmse}\n",
    "        save_json(path=Path(\"scores.json\"), data=self.scores)       \n",
    "\n",
    "    def train(self):\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=self.config.learning_rate),\n",
    "            loss='mean_squared_error'\n",
    "        ) \n",
    "        checkpoint_path = self.config.trained_model_path\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            filepath=checkpoint_path, \n",
    "            monitor='val_loss',\n",
    "            verbose=1, \n",
    "            save_best_only=True,\n",
    "            mode='min'\n",
    "        )\n",
    "        earlystopping = EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=self.config.patience, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        callbacks = [checkpoint, earlystopping]\n",
    "\n",
    "        history = self.model.fit(\n",
    "            self.trainX, \n",
    "            self.trainY, \n",
    "            batch_size=self.config.batch_size,\n",
    "            epochs=self.config.epochs,\n",
    "            verbose=1, \n",
    "            shuffle=False, \n",
    "            validation_data=(self.valX, self.valY),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        max_test = self.df_test['close'].max()\n",
    "        min_test = self.df_test['close'].min()\n",
    "        max_val = self.df_val['close'].max()\n",
    "        min_val = self.df_val['close'].min()\n",
    "        max_train = self.df_train['close'].max()\n",
    "        min_train = self.df_train['close'].min()                \n",
    "\n",
    "        train_loss = history.history['loss'][-1] * (max_train - min_train) + min_train\n",
    "        val_loss = history.history['val_loss'][-1] * (max_val - min_val) + min_val\n",
    "\n",
    "        test_predictions = self.model.predict(self.testX)\n",
    "        test_predictions = test_predictions * (max_test - min_test) + min_test\n",
    "\n",
    "        prediction=test_predictions.reshape(-1,1).flatten()[-self.config.forecast_horizon:]\n",
    "\n",
    "        self.save_prediction(prediction=prediction)\n",
    "\n",
    "\n",
    "        actual_price = self.testY * (max_test - min_test) + min_test\n",
    "\n",
    "        test_rmse = self.calculate_rmse(actual_price, test_predictions)\n",
    "\n",
    "        self.save_score(train_loss, val_loss, test_rmse)\n",
    "\n",
    "    def save_model_to_dir(self):\n",
    "        model=tf.keras.models.load_model(self.config.trained_model_path)\n",
    "        model.save(self.config.saved_model_path)\n",
    " \n",
    "    def save_prediction(self,prediction:np.array):\n",
    "         np.save(self.config.result_path,prediction)\n",
    "\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"train_loss\": self.scores[\"train_loss\"], \"val_loss\": self.scores[\"val_loss\"], \"test_rmse\": self.scores[\"test_rmse\"]}\n",
    "            )\n",
    "            if tracking_url_type_store != \"file\":\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"LSTM_BTC_PREDECTION\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-10 17:27:21,219: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-05-10 17:27:21,221: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-05-10 17:27:21,223: INFO: common: created directory at: artifacts]\n",
      "[2024-05-10 17:27:21,223: INFO: common: created directory at: artifacts/training]\n",
      "[2024-05-10 17:27:21,224: INFO: common: created directory at: model]\n",
      "[2024-05-10 17:27:21,225: INFO: common: created directory at: prediction]\n",
      "[2024-05-10 17:27:21,305: WARNING: legacy_h5_format: No training configuration found in the save file, so the model was *not* compiled. Compile it manually.]\n",
      "[2024-05-10 17:27:21,305: INFO: 2426360760: Model loaded successfully]\n",
      "[2024-05-10 17:27:21,330: INFO: 2426360760: DATA loaded successfully]\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.5467\n",
      "Epoch 1: val_loss improved from inf to 0.21577, saving model to artifacts/training/model.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 139ms/step - loss: 0.5440 - val_loss: 0.2158\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step\n",
      "[2024-05-10 17:27:35,955: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/10 17:27:36 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "Registered model 'LSTM_BTC_PREDECTION' already exists. Creating a new version of this model...\n",
      "2024/05/10 17:28:04 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM_BTC_PREDECTION, version 6\n",
      "Created version '6' of model 'LSTM_BTC_PREDECTION'.\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    config=ConfigurationManager()\n",
    "    training_config=config.get_tarining_config()\n",
    "    training=Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.get_data()\n",
    "    training.train()\n",
    "    training.log_into_mlflow()\n",
    "    training.save_model_to_dir()\n",
    "except Exception as e :\n",
    "    raise e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
